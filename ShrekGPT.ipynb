{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saumilthecode/LLM-from-Scratch/blob/main/ShrekGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybm75UCs-u49",
        "outputId": "3e56d75c-2ecd-4fd2-8b02-76f38abd1281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf26huZH9XDj",
        "outputId": "931b29d7-d1c3-4ac6-e905-c57953391230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers datasets tqdm torch torchvision torchaudio\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset , TensorDataset\n",
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Ensure GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/saumilthecode/LLM-from-Scratch/refs/heads/main/shrek1%2B3.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4NdAcFL_LBx",
        "outputId": "fa077c7d-8e7e-41b3-bbbe-7459145245a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-27 07:44:13--  https://raw.githubusercontent.com/saumilthecode/LLM-from-Scratch/refs/heads/main/shrek1%2B3.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 313093 (306K) [text/plain]\n",
            "Saving to: ‘shrek1+3.txt’\n",
            "\n",
            "\rshrek1+3.txt          0%[                    ]       0  --.-KB/s               \rshrek1+3.txt        100%[===================>] 305.75K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-09-27 07:44:13 (11.7 MB/s) - ‘shrek1+3.txt’ saved [313093/313093]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import mmap\n",
        "import random\n",
        "import pickle\n",
        "import argparse\n",
        "! pip install huggingface_hub\n",
        "! pip install transformers\n",
        "! pip install sentencepiece\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "batch_size = 64\n",
        "block_size = 128\n",
        "max_iters = 10000\n",
        "learning_rate = 1e-4\n",
        "eval_iters = 50\n",
        "n_embd = 512\n",
        "n_head = 8\n",
        "n_layer = 6\n",
        "dropout = 0.1\n",
        "\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "x_4Ai8jD_QZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ccbdc2-84a4-4538-c524-29bc10d5f8d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('shrek1+3.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "chars = sorted(set(text))\n",
        "print(chars)\n",
        "vocab_size = len(chars)\n",
        "\n",
        "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
        "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
        "\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters, device=device)  # Move tensor to GPU\n",
        "        for k in range(eval_iters):\n",
        "            # Get batch data from DataLoader\n",
        "            for X, Y in (train_loader if split == 'train' else val_loader):\n",
        "                logits, loss = model(X.to(device), Y.to(device))\n",
        "                losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()  # Set model back to training mode\n",
        "    return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pqpMDy0J_UWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)  # Set bias=False\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)  # Set bias=False\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)  # Set bias=False\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd, bias=False)  # Set bias=False\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "class FeedForward(nn.Module):  # Corrected class name\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd, bias=False),  # Set bias=False\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd, bias=False),  # Set bias=False\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)  # Changed here to FeedForward\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.sa(x)\n",
        "        x = self.ln1(x + y)\n",
        "        y = self.ffwd(x)\n",
        "        x = self.ln2(x + y)\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)  # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "\n",
        "        tok_emb = self.token_embedding_table(index)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            index_cond = index[:, -block_size:]\n",
        "            logits, loss = self.forward(index_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            index_next = torch.multinomial(probs, num_samples=1)\n",
        "            index = torch.cat((index, index_next), dim=1)\n",
        "        return index\n",
        "\n",
        "model = GPTLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "znzMpVox_cWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "\n",
        "# Create TensorDatasets for training and validation\n",
        "train_dataset = TensorDataset(train_data)\n",
        "val_dataset = TensorDataset(val_data)\n",
        "\n",
        "# Use DataLoader with multiple workers\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)  # Adjust num_workers based on your CPU cores\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "accumulation_steps = 4  # Adjust this value as per your needs\n",
        "scaler = GradScaler()\n",
        "optimizer.zero_grad(set_to_none=True)  # Initialize optimizer\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    print(f\"Iteration {iter}\")\n",
        "\n",
        "    if iter % eval_iters == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
        "\n",
        "    # Load batch data from the DataLoader\n",
        "    for xb, yb in train_loader:  # Use the DataLoader here\n",
        "        with autocast():\n",
        "            logits, loss = model(xb.to(device), yb.to(device))  # Move data to the appropriate device\n",
        "            loss = loss / accumulation_steps  # Normalize loss for accumulation\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (iter + 1) % accumulation_steps == 0:\n",
        "            scaler.step(optimizer)  # Update model parameters\n",
        "            scaler.update()  # Update scaler for mixed precision\n",
        "            optimizer.zero_grad(set_to_none=True)  # Reset gradients after step\n",
        "\n",
        "# Print the final loss after training\n",
        "print(loss.item())\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n"
      ],
      "metadata": {
        "id": "nwgi4BSL_eC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'battle of midway'\n",
        "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=100)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "id": "ZuO443oA_g-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONE MASSIVE HUNKA CODE\n"
      ],
      "metadata": {
        "id": "hvW5CLcJPqGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers datasets tqdm torch torchvision torchaudio sentencepiece huggingface_hub\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Ensure GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Parameters\n",
        "batch_size = 64\n",
        "block_size = 128\n",
        "max_iters = 10000\n",
        "learning_rate = 1e-4\n",
        "eval_iters = 50\n",
        "n_embd = 512\n",
        "n_head = 8\n",
        "n_layer = 6\n",
        "dropout = 0.1\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Load and process text data\n",
        "with open('shrek1+3.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(set(text))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
        "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
        "\n",
        "# Encode dataset\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "train_dataset = TensorDataset(train_data)\n",
        "val_dataset = TensorDataset(val_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Function to generate batches\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "# Loss estimation\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters, device=device)\n",
        "        loader = train_loader if split == 'train' else val_loader\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean().item()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "# Model components\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)  # (B, T, head_size)\n",
        "        q = self.query(x)  # (B, T, head_size)\n",
        "        v = self.value(x)  # (B, T, head_size)\n",
        "\n",
        "        # Compute attention scores\n",
        "        wei = q @ k.transpose(-2, -1) * (1.0 / (k.shape[-1] ** 0.5))  # scaled dot-product attention\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))  # apply mask\n",
        "        wei = torch.nn.functional.softmax(wei, dim=-1)  # attention weights\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        # Weighted sum of values\n",
        "        out = wei @ v  # (B, T, head_size)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd, bias=False),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.sa(x)\n",
        "        x = self.ln1(x + y)\n",
        "        y = self.ffwd(x)\n",
        "        x = self.ln2(x + y)\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "        tok_emb = self.token_embedding_table(index)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets[:, :T].contiguous().view(B * T)\n",
        "            loss = nn.CrossEntropyLoss()(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            index_cond = index[:, -block_size:]\n",
        "            logits, loss = self(index_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            index_next = torch.multinomial(probs, num_samples=1)\n",
        "            index = torch.cat((index, index_next), dim=1)\n",
        "        return index\n",
        "\n",
        "# Instantiate model\n",
        "model = GPTLanguageModel(vocab_size)\n",
        "model = model.to(device)\n",
        "\n",
        "# Optimizer and AMP scaler\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Training loop\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_iters == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
        "\n",
        "    x_batch, y_batch = get_batch('train')\n",
        "    with torch.cuda.amp.autocast():\n",
        "        logits, loss = model(x_batch, y_batch)\n",
        "\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "# Final testing - Text generation\n",
        "prompt = 'battle of midway'\n",
        "context = torch.tensor(encode(prompt), dtype=torch.long, device=device).unsqueeze(0)\n",
        "generated_text = decode(model.generate(context, max_new_tokens=100)[0].tolist())\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNmkDeYWPr6T",
        "outputId": "073b0c85-6156-492d-e47f-7001a1ff0bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9a3ffbbe29cb>:201: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, train loss: 4.496, val loss: 4.480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9a3ffbbe29cb>:210: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 50, train loss: 2.027, val loss: 1.756\n",
            "step: 100, train loss: 1.896, val loss: 1.662\n",
            "step: 150, train loss: 1.800, val loss: 1.552\n",
            "step: 200, train loss: 1.695, val loss: 1.450\n",
            "step: 250, train loss: 1.647, val loss: 1.393\n",
            "step: 300, train loss: 1.533, val loss: 1.308\n",
            "step: 350, train loss: 1.466, val loss: 1.225\n",
            "step: 400, train loss: 1.410, val loss: 1.200\n",
            "step: 450, train loss: 1.360, val loss: 1.143\n",
            "step: 500, train loss: 1.307, val loss: 1.098\n",
            "step: 550, train loss: 1.266, val loss: 1.077\n",
            "step: 600, train loss: 1.248, val loss: 1.052\n",
            "step: 650, train loss: 1.183, val loss: 1.018\n",
            "step: 700, train loss: 1.164, val loss: 0.996\n",
            "step: 750, train loss: 1.121, val loss: 0.977\n",
            "step: 800, train loss: 1.115, val loss: 0.952\n",
            "step: 850, train loss: 1.093, val loss: 0.947\n",
            "step: 900, train loss: 1.080, val loss: 0.924\n",
            "step: 950, train loss: 1.052, val loss: 0.903\n",
            "step: 1000, train loss: 1.026, val loss: 0.915\n",
            "step: 1050, train loss: 1.027, val loss: 0.884\n",
            "step: 1100, train loss: 0.998, val loss: 0.862\n",
            "step: 1150, train loss: 0.984, val loss: 0.858\n",
            "step: 1200, train loss: 0.971, val loss: 0.862\n",
            "step: 1250, train loss: 0.955, val loss: 0.850\n",
            "step: 1300, train loss: 0.934, val loss: 0.842\n",
            "step: 1350, train loss: 0.913, val loss: 0.822\n",
            "step: 1400, train loss: 0.915, val loss: 0.824\n",
            "step: 1450, train loss: 0.905, val loss: 0.818\n",
            "step: 1500, train loss: 0.900, val loss: 0.830\n",
            "step: 1550, train loss: 0.877, val loss: 0.822\n",
            "step: 1600, train loss: 0.867, val loss: 0.803\n",
            "step: 1650, train loss: 0.867, val loss: 0.791\n",
            "step: 1700, train loss: 0.835, val loss: 0.788\n",
            "step: 1750, train loss: 0.833, val loss: 0.796\n",
            "step: 1800, train loss: 0.828, val loss: 0.803\n",
            "step: 1850, train loss: 0.809, val loss: 0.779\n",
            "step: 1900, train loss: 0.797, val loss: 0.774\n",
            "step: 1950, train loss: 0.795, val loss: 0.779\n",
            "step: 2000, train loss: 0.773, val loss: 0.784\n",
            "step: 2050, train loss: 0.774, val loss: 0.770\n",
            "step: 2100, train loss: 0.764, val loss: 0.778\n",
            "step: 2150, train loss: 0.753, val loss: 0.780\n",
            "step: 2200, train loss: 0.740, val loss: 0.780\n",
            "step: 2250, train loss: 0.733, val loss: 0.767\n",
            "step: 2300, train loss: 0.718, val loss: 0.775\n",
            "step: 2350, train loss: 0.698, val loss: 0.767\n",
            "step: 2400, train loss: 0.708, val loss: 0.771\n",
            "step: 2450, train loss: 0.699, val loss: 0.771\n",
            "step: 2500, train loss: 0.683, val loss: 0.782\n",
            "step: 2550, train loss: 0.660, val loss: 0.770\n",
            "step: 2600, train loss: 0.662, val loss: 0.778\n",
            "step: 2650, train loss: 0.651, val loss: 0.770\n",
            "step: 2700, train loss: 0.643, val loss: 0.799\n",
            "step: 2750, train loss: 0.633, val loss: 0.784\n",
            "step: 2800, train loss: 0.622, val loss: 0.789\n",
            "step: 2850, train loss: 0.617, val loss: 0.782\n",
            "step: 2900, train loss: 0.600, val loss: 0.797\n",
            "step: 2950, train loss: 0.600, val loss: 0.763\n",
            "step: 3000, train loss: 0.583, val loss: 0.791\n",
            "step: 3050, train loss: 0.573, val loss: 0.793\n",
            "step: 3100, train loss: 0.564, val loss: 0.794\n",
            "step: 3150, train loss: 0.554, val loss: 0.798\n",
            "step: 3200, train loss: 0.543, val loss: 0.807\n",
            "step: 3250, train loss: 0.542, val loss: 0.805\n",
            "step: 3300, train loss: 0.524, val loss: 0.794\n",
            "step: 3350, train loss: 0.514, val loss: 0.791\n",
            "step: 3400, train loss: 0.512, val loss: 0.812\n",
            "step: 3450, train loss: 0.494, val loss: 0.809\n",
            "step: 3500, train loss: 0.483, val loss: 0.809\n",
            "step: 3550, train loss: 0.479, val loss: 0.819\n",
            "step: 3600, train loss: 0.473, val loss: 0.836\n",
            "step: 3650, train loss: 0.461, val loss: 0.833\n",
            "step: 3700, train loss: 0.451, val loss: 0.833\n",
            "step: 3750, train loss: 0.436, val loss: 0.840\n",
            "step: 3800, train loss: 0.433, val loss: 0.857\n",
            "step: 3850, train loss: 0.417, val loss: 0.853\n",
            "step: 3900, train loss: 0.416, val loss: 0.872\n",
            "step: 3950, train loss: 0.405, val loss: 0.863\n",
            "step: 4000, train loss: 0.391, val loss: 0.868\n",
            "step: 4050, train loss: 0.386, val loss: 0.863\n",
            "step: 4100, train loss: 0.385, val loss: 0.879\n",
            "step: 4150, train loss: 0.364, val loss: 0.871\n",
            "step: 4200, train loss: 0.361, val loss: 0.896\n",
            "step: 4250, train loss: 0.355, val loss: 0.905\n",
            "step: 4300, train loss: 0.342, val loss: 0.898\n",
            "step: 4350, train loss: 0.333, val loss: 0.913\n",
            "step: 4400, train loss: 0.328, val loss: 0.918\n",
            "step: 4450, train loss: 0.319, val loss: 0.908\n",
            "step: 4500, train loss: 0.318, val loss: 0.928\n",
            "step: 4550, train loss: 0.305, val loss: 0.932\n",
            "step: 4600, train loss: 0.301, val loss: 0.949\n",
            "step: 4650, train loss: 0.296, val loss: 0.956\n",
            "step: 4700, train loss: 0.288, val loss: 0.944\n",
            "step: 4750, train loss: 0.283, val loss: 0.958\n",
            "step: 4800, train loss: 0.273, val loss: 0.962\n",
            "step: 4850, train loss: 0.265, val loss: 0.977\n",
            "step: 4900, train loss: 0.263, val loss: 0.992\n",
            "step: 4950, train loss: 0.256, val loss: 0.980\n",
            "step: 5000, train loss: 0.249, val loss: 0.999\n",
            "step: 5050, train loss: 0.243, val loss: 0.995\n",
            "step: 5100, train loss: 0.241, val loss: 1.007\n",
            "step: 5150, train loss: 0.233, val loss: 1.011\n",
            "step: 5200, train loss: 0.233, val loss: 1.035\n",
            "step: 5250, train loss: 0.229, val loss: 1.033\n",
            "step: 5300, train loss: 0.225, val loss: 1.019\n",
            "step: 5350, train loss: 0.223, val loss: 1.029\n",
            "step: 5400, train loss: 0.216, val loss: 1.039\n",
            "step: 5450, train loss: 0.213, val loss: 1.063\n",
            "step: 5500, train loss: 0.208, val loss: 1.037\n",
            "step: 5550, train loss: 0.204, val loss: 1.044\n",
            "step: 5600, train loss: 0.200, val loss: 1.062\n",
            "step: 5650, train loss: 0.195, val loss: 1.089\n",
            "step: 5700, train loss: 0.196, val loss: 1.066\n",
            "step: 5750, train loss: 0.195, val loss: 1.096\n",
            "step: 5800, train loss: 0.188, val loss: 1.091\n",
            "step: 5850, train loss: 0.184, val loss: 1.090\n",
            "step: 5900, train loss: 0.183, val loss: 1.094\n",
            "step: 5950, train loss: 0.182, val loss: 1.114\n",
            "step: 6000, train loss: 0.178, val loss: 1.106\n",
            "step: 6050, train loss: 0.178, val loss: 1.130\n",
            "step: 6100, train loss: 0.175, val loss: 1.113\n",
            "step: 6150, train loss: 0.173, val loss: 1.135\n",
            "step: 6200, train loss: 0.169, val loss: 1.137\n",
            "step: 6250, train loss: 0.169, val loss: 1.144\n",
            "step: 6300, train loss: 0.168, val loss: 1.132\n",
            "step: 6350, train loss: 0.164, val loss: 1.166\n",
            "step: 6400, train loss: 0.163, val loss: 1.160\n",
            "step: 6450, train loss: 0.160, val loss: 1.162\n",
            "step: 6500, train loss: 0.160, val loss: 1.172\n",
            "step: 6550, train loss: 0.160, val loss: 1.169\n",
            "step: 6600, train loss: 0.158, val loss: 1.184\n",
            "step: 6650, train loss: 0.157, val loss: 1.152\n",
            "step: 6700, train loss: 0.157, val loss: 1.198\n",
            "step: 6750, train loss: 0.154, val loss: 1.195\n",
            "step: 6800, train loss: 0.154, val loss: 1.184\n",
            "step: 6850, train loss: 0.152, val loss: 1.195\n",
            "step: 6900, train loss: 0.151, val loss: 1.238\n",
            "step: 6950, train loss: 0.150, val loss: 1.205\n",
            "step: 7000, train loss: 0.149, val loss: 1.242\n",
            "step: 7050, train loss: 0.149, val loss: 1.219\n",
            "step: 7100, train loss: 0.147, val loss: 1.231\n",
            "step: 7150, train loss: 0.146, val loss: 1.252\n",
            "step: 7200, train loss: 0.146, val loss: 1.255\n",
            "step: 7250, train loss: 0.143, val loss: 1.247\n",
            "step: 7300, train loss: 0.146, val loss: 1.258\n",
            "step: 7350, train loss: 0.143, val loss: 1.249\n",
            "step: 7400, train loss: 0.142, val loss: 1.294\n",
            "step: 7450, train loss: 0.142, val loss: 1.256\n",
            "step: 7500, train loss: 0.141, val loss: 1.270\n",
            "step: 7550, train loss: 0.141, val loss: 1.266\n",
            "step: 7600, train loss: 0.138, val loss: 1.288\n",
            "step: 7650, train loss: 0.140, val loss: 1.303\n",
            "step: 7700, train loss: 0.139, val loss: 1.283\n",
            "step: 7750, train loss: 0.138, val loss: 1.303\n",
            "step: 7800, train loss: 0.137, val loss: 1.271\n",
            "step: 7850, train loss: 0.136, val loss: 1.320\n",
            "step: 7900, train loss: 0.137, val loss: 1.284\n",
            "step: 7950, train loss: 0.134, val loss: 1.309\n",
            "step: 8000, train loss: 0.136, val loss: 1.312\n",
            "step: 8050, train loss: 0.135, val loss: 1.324\n",
            "step: 8100, train loss: 0.134, val loss: 1.309\n",
            "step: 8150, train loss: 0.135, val loss: 1.302\n",
            "step: 8200, train loss: 0.133, val loss: 1.340\n",
            "step: 8250, train loss: 0.133, val loss: 1.293\n",
            "step: 8300, train loss: 0.132, val loss: 1.297\n",
            "step: 8350, train loss: 0.132, val loss: 1.325\n",
            "step: 8400, train loss: 0.133, val loss: 1.325\n",
            "step: 8450, train loss: 0.129, val loss: 1.344\n",
            "step: 8500, train loss: 0.131, val loss: 1.314\n",
            "step: 8550, train loss: 0.130, val loss: 1.340\n",
            "step: 8600, train loss: 0.131, val loss: 1.322\n",
            "step: 8650, train loss: 0.129, val loss: 1.350\n",
            "step: 8700, train loss: 0.127, val loss: 1.358\n",
            "step: 8750, train loss: 0.128, val loss: 1.337\n",
            "step: 8800, train loss: 0.127, val loss: 1.339\n",
            "step: 8850, train loss: 0.128, val loss: 1.348\n",
            "step: 8900, train loss: 0.127, val loss: 1.352\n",
            "step: 8950, train loss: 0.125, val loss: 1.365\n",
            "step: 9000, train loss: 0.125, val loss: 1.368\n",
            "step: 9050, train loss: 0.126, val loss: 1.378\n",
            "step: 9100, train loss: 0.126, val loss: 1.413\n",
            "step: 9150, train loss: 0.126, val loss: 1.364\n",
            "step: 9200, train loss: 0.126, val loss: 1.390\n",
            "step: 9250, train loss: 0.126, val loss: 1.381\n",
            "step: 9300, train loss: 0.123, val loss: 1.366\n",
            "step: 9350, train loss: 0.124, val loss: 1.390\n",
            "step: 9400, train loss: 0.123, val loss: 1.394\n",
            "step: 9450, train loss: 0.124, val loss: 1.411\n",
            "step: 9500, train loss: 0.122, val loss: 1.396\n",
            "step: 9550, train loss: 0.122, val loss: 1.386\n",
            "step: 9600, train loss: 0.121, val loss: 1.377\n",
            "step: 9650, train loss: 0.122, val loss: 1.427\n",
            "step: 9700, train loss: 0.122, val loss: 1.397\n",
            "step: 9750, train loss: 0.123, val loss: 1.373\n",
            "step: 9800, train loss: 0.121, val loss: 1.426\n",
            "step: 9850, train loss: 0.120, val loss: 1.433\n",
            "step: 9900, train loss: 0.121, val loss: 1.444\n",
            "step: 9950, train loss: 0.121, val loss: 1.422\n",
            "battle of midway. Oh, you \n",
            "look at it 'care. I'm a sorry about me, \n",
            "I'd everyther see it.\n",
            "\n",
            "I've beast alking strimse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'shrek'\n",
        "context = torch.tensor(encode(prompt), dtype=torch.long, device=device).unsqueeze(0)\n",
        "generated_text = decode(model.generate(context, max_new_tokens=10)[0].tolist())\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNRCk6DjgWvP",
        "outputId": "83989f39-07ae-4482-d648-0697eea24aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shrek and at th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = \"gpt_model.pt\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "# Save the model weights\n",
        "torch.save(model.state_dict(), 'custom_gpt_model.pth')\n"
      ],
      "metadata": {
        "id": "vK78dGxtxtDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install huggingface_hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-kuPhvdyTUQ",
        "outputId": "7d10e93d-a260-4e83-95a0-a299ab8db380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "userdata.get('HF')\n",
        "\n",
        "# Log in to Hugging Face\n",
        "login(\"HF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "hOYCuZv6yVm2",
        "outputId": "77bce44e-ef59-4343-8bef-0d21649fb972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid token passed!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-04ef151230e5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Log in to Hugging Face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(token, add_to_git_credential, new_session, write_permission)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;34m\"you want to set the git credential as well.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             )\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0m_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_to_git_credential\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_to_git_credential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_permission\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwrite_permission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mnotebook_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_permission\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwrite_permission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(token, add_to_git_credential, write_permission)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0mpermission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token_permission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpermission\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid token passed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mwrite_permission\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpermission\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid token passed!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, Repository\n",
        "\n",
        "# Create a repository on Hugging Face\n",
        "repo_name = \"saumil707/SHREKGPT\"  # Choose a unique name for your model\n",
        "api = HfApi()\n",
        "api.create_repo(repo_name)\n",
        "\n",
        "# Push the model\n",
        "repo = Repository(local_dir=repo_name, clone_from=repo_name)\n",
        "repo.git_add()\n",
        "repo.git_commit(\"Initial commit of the model\")\n",
        "repo.git_push()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "id": "rhagZlqEynO7",
        "outputId": "2869a1a7-60c2-45f7-c29b-199b8a4d8d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/saumil707/SHREKGPT into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/saumil707/SHREKGPT into local empty directory.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Author identity unknown\n\n*** Please tell me who you are.\n\nRun\n\n  git config --global user.email \"you@example.com\"\n  git config --global user.name \"Your Name\"\n\nto set your account's default identity.\nOmit --global to set the identity only in this repository.\n\nfatal: unable to auto-detect email address (got 'root@2e05bcb8600f.(none)')\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mgit_commit\u001b[0;34m(self, commit_message)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_subprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"git commit -v -m\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcommit_message\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Committed:\\n{result.stdout}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_subprocess.py\u001b[0m in \u001b[0;36mrun_subprocess\u001b[0;34m(command, folder, check, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     return subprocess.run(\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    527\u001b[0m                                      output=stdout, stderr=stderr)\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['git', 'commit', '-v', '-m', 'Initial commit of the model']' returned non-zero exit status 128.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7f4d4a9474a5>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrepo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_commit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial commit of the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mrepo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgit_push\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/repository.py\u001b[0m in \u001b[0;36mgit_commit\u001b[0;34m(self, commit_message)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Author identity unknown\n\n*** Please tell me who you are.\n\nRun\n\n  git config --global user.email \"you@example.com\"\n  git config --global user.name \"Your Name\"\n\nto set your account's default identity.\nOmit --global to set the identity only in this repository.\n\nfatal: unable to auto-detect email address (got 'root@2e05bcb8600f.(none)')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "l3-ftiO1y1AI",
        "outputId": "6f3a3978-4e31-4843-901a-d4347008f490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-22-a6a3ea0d01f8>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-a6a3ea0d01f8>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    git config --global user.email \"saumil707@gmail.com\"\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZHM3krMzANM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}